\documentclass[../../cs-notes.tex]{subfiles}

\title{Machine learning}
\author{Benjamin Boboul}
\date{\today}

\begin{document}
	\maketitle

	Ce document concat\`ene un ensemble de notes diverses portant sur le \textit{Machine Learning}.
	C'est une manière pour moi de m'engager dans l'apprentissage de ce domaine et de garder une trace de mes progrès.
	Si ce document se r\'ev\`ele vous être utile ou que vous remarquez des erreurs de ma part, merci de me communiquer toutes remarques.
	Contact: benjamin.boboul@imt-lille-douai.org

	\part{Feature engineering \& preprocessing}

	\paragraph{StandarScaler} \textit{Scikit-learn} propose diverses fonction de prétraitement, \textit{StandarScaler} s'assure que les échantillons aient une moyenne nulle et une variance de 1.

	\paragraph{RobustScaler} Similaire à \textit{StandarScaler}, 

	\paragraph{PCA} L'analyse en composantes principales (ACP) consiste à calculer les composantes principales et à les utiliser pour effectuer un changement de base sur les données, en utilisant parfois uniquement les quelques premières composantes principales et en ignorant le reste. 
	L'ACP est utilisée dans l'analyse exploratoire des données et pour élaborer des modèles prédictifs.
	Elle est couramment utilisée pour la réduction de la dimensionnalité en projetant chaque point de données sur seulement les quelques premières composantes principales afin d'obtenir des données de plus faible dimension tout en préservant autant que possible la variation des données.

	\part{Supervised learning}

	\input{notes/machine-learning/introduction.tex}
	\input{notes/machine-learning/linear-regression/linear-regression}
	\input{notes/machine-learning/logistic-regression/logistic-regression}
	\input{notes/machine-learning/knn/knn}
	\input{notes/machine-learning/svm/svm}
	\input{notes/machine-learning/tree-based-methods/decision-tree}
	\input{notes/machine-learning/tree-based-methods/random-forests}
	\input{notes/machine-learning/ann/ann}
	\input{notes/machine-learning/cnn/cnn}
	\input{notes/machine-learning/rnn/rnn}

	\part{Unsupervised learning}

	À la différence de l'apprentissage supervisé, nos données ne disposent pas de labels.
	Impossible donc d'entraîner un algorithme en fonction d'une valeur attendue, cette solution permet cependant d'identifier des motifs dans notre jeu de données.

	\paragraph{Application d'apprentissage non-supervisé}
	Parmis les applications d'apprentissage non-supervisé, nous allons dénoter une utilisation plus fréquente dans le cadre de la détection d'anomalies et la segmentation en groupe.

	\subparagraph{Anomaly Detection} Les système de détections d'anomalies sont utilisé pour repérer des fraudes ou des évènements qui dénotent d'une certaine tendance.

	\subparagraph{Group segmentation}
	Les algorithmes de segmentation sont utilisé pour classifier du contenu, des données en fonction de leurs similarités.

	\chapter{Réduction de dimensions}
	\section{Projection linéaire}
	\section{Manifold Learning}


	\chapter{Clustering}
	Utiliser un algorithme de \textit{clustering} vise à identifier différentes classes d'un jeu de données.
	Pour ce faire, on identifie plusieurs sous-ensembles que l'on groupe en fonction de leurs similarités.

	\section{K-means}


	\section{DBSCAN}
	\textsc{dbscan} utilise un paramètre \textit{min\_samples} pour identifier les sous-ensembles de taille suffisante.
	Si deux sous-ensembles sont à proximité, celui dont la densité est la plus grande l'emporte sur le second.

	\inputminted{python}{code/machine-learning/unsupervised-learning/dbscan.py}

	\chapter{Feature Extraction}

	\section{Autoencoders}

	\input{notes/machine-learning/unsupervised/SOM/SOM}


\end{document}
